ğŸ¤ Speech Emotion Recognition Web App
A machine learningâ€“powered web application that detects human emotions from speech audio using MFCC features and an SVM classifier, deployed with Streamlit.

ğŸŒ Live Application Overview
This web app allows users to:

Upload a .wav audio file

Analyze the speech signal

Predict the emotion expressed in the audio

ğŸ¯ Supported Emotions

Neutral

Calm

Happy

Sad

Angry

Fear

Disgust

Surprise

ğŸ§  How It Works (Highâ€‘Level)
Audio Input

User uploads a WAV file through the web interface

Feature Extraction

Mel Frequency Cepstral Coefficients (MFCCs) are extracted from audio

MFCCs capture speech characteristics similar to human hearing

Model Prediction

A Support Vector Machine (SVM) model classifies the emotion

Output is displayed instantly on the UI

ğŸ› ï¸ Tech Stack
Category	Technology
Language	Python
ML Model	Support Vector Machine (SVM)
Feature Extraction	Librosa (MFCC)
Web Framework	Streamlit
Dataset	RAVDESS (Ryerson Audioâ€‘Visual Dataset)
Libraries	NumPy, Pandas, Scikitâ€‘Learn
ğŸ“ Project Structure
emotion-recognition/
â”‚
â”œâ”€â”€ app.py                 # Streamlit frontend
â”œâ”€â”€ backend.py             # ML logic (training + inference)
â”œâ”€â”€ audio/                 # Training dataset (RAVDESS)
â”œâ”€â”€ uploads/               # Uploaded audio files
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸš€ How to Run the Project Locally
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/emotion-recognition.git
cd emotion-recognition
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
3ï¸âƒ£ Run the Web App
streamlit run app.py
The app will open automatically in your browser.

ğŸ“Š Machine Learning Details
Algorithm: Support Vector Machine (RBF Kernel)

Features: 40 MFCC coefficients

Scaling: StandardScaler

Train-Test Split: 80% / 20%

Dataset: RAVDESS (Emotionâ€‘labeled speech dataset)

ğŸ“ˆ Results
Achieved high classification accuracy on validation data

SVM performed better than Random Forest for MFCCâ€‘based features

Realâ€‘time predictions through web UI

ğŸ¯ Use Cases
Emotion analysis in voice assistants

Mental health monitoring systems

Callâ€‘center sentiment analysis

Humanâ€‘computer interaction (HCI)

AIâ€‘based speech analytics

ğŸ”® Future Enhancements
ğŸ™ï¸ Live microphone recording

ğŸ§  Gender detection from voice

ğŸ“Š Confusion matrix & model insights

â˜ï¸ Cloud deployment (Streamlit Cloud / AWS)

ğŸ“± Mobileâ€‘friendly UI

ğŸ‘¨â€ğŸ’» Contributors
Mohammed Ghias Pasha

Artham Praneeth


### Dataset:https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio


### testing Audio:https://www.kaggle.com/datasets/pavanelisetty/sample-audio-files-for-speech-recognition
